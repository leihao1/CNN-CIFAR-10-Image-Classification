{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sets\n",
    "DATA_PATH = 'dataset/'\n",
    "IMAGE_PATH = 'image/'\n",
    "files = []\n",
    "dfs = []\n",
    "dfs_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(X):\n",
    "    plt.figure(figsize=(50,5))\n",
    "    for i,x in enumerate(X[:10]):\n",
    "        plt.subplot(1,10,i+1)\n",
    "        try:\n",
    "            plt.imshow(np.array(x))\n",
    "        except:\n",
    "            plt.imshow(np.array(x).transpose(1,2,0))\n",
    "    \n",
    "def dimension_reduction(x_train, x_test, n_components):\n",
    "    print(\"Reducting dimensions...\")\n",
    "    pca = PCA(n_components=n_components, random_state=33)\n",
    "    pca.fit(x_train)\n",
    "    x_train= pca.transform(x_train)\n",
    "    x_test = pca.transform(x_test)\n",
    "    return x_train, x_test, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR_10(training_batches=5, test_batches=1):\n",
    "    X_train=y_train=X_test=y_test = None\n",
    "    for b in range(1,training_batches+1):\n",
    "        with open(DATA_PATH+'data_batch_%s'%b,'rb') as file:\n",
    "            data = pickle.load(file,encoding='bytes')\n",
    "            X = np.array(data[b'data'])\n",
    "            y = np.array(data[b'labels'])\n",
    "            try:\n",
    "                X_train = np.concatenate((X_train,X))\n",
    "                y_train = np.concatenate((y_train,y))\n",
    "                print('train set batch: %d'%b)\n",
    "            except:\n",
    "                print('train set batch: %d'%b)\n",
    "                X_train = X\n",
    "                y_train = y\n",
    "                \n",
    "    for b in range(1,test_batches+1):\n",
    "        with open(DATA_PATH+'test_batch','rb') as file:\n",
    "            data = pickle.load(file,encoding='bytes')\n",
    "            X = np.array(data[b'data'])\n",
    "            y = np.array(data[b'labels'])\n",
    "            try:\n",
    "                X_test = np.concatenate((X_test,X))\n",
    "                y_test = np.concatenate((y_test,y))\n",
    "            except:\n",
    "                print('test set batch: %d'%b)\n",
    "                X_test = X\n",
    "                y_test = y\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_two_component(comp1,comp2,y_train,classes,save_as):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    color_map = plt.cm.get_cmap('Accent')\n",
    "    \n",
    "    #plot without labels (faster)\n",
    "    plt.scatter(comp1,comp2,c=y_train,cmap=color_map)\n",
    "\n",
    "    #plot labels\n",
    "    labels = np.array(classes)[y_train]\n",
    "    class_num = set()\n",
    "    for x1,x2,c,l in zip(comp1,comp2,color_map(y_train),labels):\n",
    "        if len(class_num)==10:\n",
    "            break\n",
    "        plt.scatter(x1,x2,c=[c],label=l)\n",
    "        class_num.add(l)\n",
    "        \n",
    "    #remvoe duplicate labels    \n",
    "    hand, labl = plt.gca().get_legend_handles_labels()\n",
    "    handout=[]\n",
    "    lablout=[]\n",
    "    for h,l in zip(hand,labl):\n",
    "        if l not in lablout:\n",
    "            lablout.append(l)\n",
    "            handout.append(h)\n",
    "    plt.title(save_as)\n",
    "    plt.xlabel('Component One')\n",
    "    plt.ylabel('Component Two')\n",
    "    plt.legend(handout, lablout,fontsize=20)\n",
    "    plt.savefig(IMAGE_PATH+save_as)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,y_train,X_test,y_test = load_CIFAR_10()\n",
    "# X_train,X_test,pca = dimension_reduction(X_train,X_test,n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_two_component(X_train[:,0],X_train[:,1],y_train,classes,'PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     with open('X_embedded','rb') as file:\n",
    "#         X_embedded = pickle.load(file)\n",
    "# except:\n",
    "#     X_embedded = TSNE(n_components=2).fit_transform(X_train)\n",
    "#     with open('X_embedded','wb') as file:\n",
    "#         pickle.dump(X_embedded,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_two_component(X_embedded[:,0],X_embedded[:,1],y_train,classes,'t-SNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test = load_CIFAR_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.reshape(-1,3,32,32))\n",
    "X_test = torch.tensor(X_test.reshape(-1,3,32,32))\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform functions\n",
    "T = Compose([\n",
    "    ToPILImage(),\n",
    "#     CenterCrop(32),\n",
    "#     ColorJitter(brightness=1, contrast=0, saturation=0, hue=0),\n",
    "#     Pad(2, fill=(100,100,100), padding_mode='constant'),\n",
    "#     Grayscale(3),    \n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "#     RandomAffine(30, translate=None, scale=None, shear=None, resample=False, fillcolor=0),\n",
    "#     RandomCrop(32, padding=None, pad_if_needed=False, fill=0, padding_mode='constant'),\n",
    "#     RandomPerspective(distortion_scale=0.3, p=0.5, interpolation=3),\n",
    "#     RandomRotation(10, resample=False, expand=False, center=None),\n",
    "    RandomResizedCrop(32, scale=(0.75, 1), ratio=(0.75, 1.25), interpolation=2),\n",
    "    ToTensor(),\n",
    "#     Normalize((0.4753,0.4623,0.4149), (0.2414,0.236,0.2419)),\n",
    "#     Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "])\n",
    "\n",
    "# tranform functions\n",
    "T2 = Compose([\n",
    "    ToPILImage(),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "# tranform functions\n",
    "T3 = Compose([\n",
    "    ToPILImage(),\n",
    "#     CenterCrop(32),\n",
    "#     ColorJitter(brightness=1, contrast=0, saturation=0, hue=0),\n",
    "#     Pad(2, fill=(100,100,100), padding_mode='constant'),\n",
    "    Grayscale(3),    \n",
    "#     RandomHorizontalFlip(p=0.5),\n",
    "#     RandomAffine(30, translate=None, scale=None, shear=None, resample=False, fillcolor=0),\n",
    "#     RandomCrop(32, padding=None, pad_if_needed=False, fill=0, padding_mode='constant'),\n",
    "#     RandomPerspective(distortion_scale=0.3, p=0.5, interpolation=3),\n",
    "#     RandomRotation(10, resample=False, expand=False, center=None),\n",
    "#     RandomResizedCrop(32, scale=(0.75, 1), ratio=(0.75, 1.25), interpolation=2),\n",
    "    ToTensor(),\n",
    "    Normalize((0.4753,0.4623,0.4149), (0.2414,0.236,0.2419)),\n",
    "#     Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = torch.stack([T(x) for x in X_train])\n",
    "X_train = torch.stack([T2(x) for x in X_train])\n",
    "X_test = torch.stack([T2(x) for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = X_train.shape[1]\n",
    "H = X_train.shape[2]\n",
    "W = X_train.shape[3]\n",
    "X_aug = torch.stack([X_new,X_train]).reshape(-1,C,H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_aug\n",
    "y_train = torch.stack([y_train,y_train]).reshape(-1,)\n",
    "\n",
    "X_train = torch.stack([T3(x) for x in X_train])\n",
    "X_test = torch.stack([T3(x) for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn parameters\n",
    "image_channels = X_train.shape[1]\n",
    "image_width = X_train.shape[2]\n",
    "num_filters = 32\n",
    "num_filters2 = 64\n",
    "num_filters3 = 128\n",
    "filter_size = 5\n",
    "pool_size = 2\n",
    "# final_input = (((image_width+1-filter_size)//pool_size+1-filter_size)//pool_size)**2*num_filters2#without padding\n",
    "final_input = (image_width//pool_size//pool_size//pool_size)**2*num_filters3#with padding\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(image_channels, num_filters, filter_size, padding=filter_size//2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(pool_size, pool_size),\n",
    "    \n",
    "    torch.nn.Conv2d(num_filters, num_filters2, filter_size, padding=filter_size//2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(pool_size, pool_size),\n",
    "    \n",
    "    torch.nn.Conv2d(num_filters2, num_filters3, filter_size, padding=filter_size//2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(pool_size, pool_size),\n",
    "    \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(final_input, final_input//2),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Linear(final_input//2, final_input//4),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Linear(final_input//4, final_input//16),\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.Linear(final_input//16,10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device.type != 'cpu':\n",
    "    print(device)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_models(model,model2,X_train,X_test,y_train,y_test,final_input,batch_size,num_epoch):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    #mini-batch training loop\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            X, y = data\n",
    "            if device.type != 'cpu':\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             optimizer2.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "\n",
    "            y_pred = model(X)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #avg batch loss\n",
    "            running_loss += loss.item()\n",
    "            batch = X_train.shape[0]//batch_size//3\n",
    "            if (i+1) % batch == 0:\n",
    "                print('Epoch: %d, Batch: %5d had avg loss: %.3f'%(epoch+1,i+1,running_loss/batch))\n",
    "                running_loss = 0.0\n",
    "        if (epoch+1) % 10 ==0:\n",
    "            torch.save(model.state_dict(), 'model_%s.pt'%(epoch+1))\n",
    "    torch.save(model.state_dict(), 'model.pt')\n",
    "    print('Training Finished')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "batch_size=16\n",
    "num_epoch=1\n",
    "# create torch Dataset class from tensors\n",
    "train_set = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_set = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "try:#try to load trained model \n",
    "    model.load_state_dict(torch.load('model.pt'))\n",
    "    print(\"Trained model loaded\")\n",
    "\n",
    "except:\n",
    "    print('Model not found, start straining...')\n",
    "    model = train_models(model,None,X_train,X_test,y_train,y_test,final_input,batch_size,num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epoch=100\n",
    "# model = train_models(batch_size,num_epoch,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        X, y = data\n",
    "        if device.type != 'cpu':\n",
    "            X, y = X.to(device), y.to(device) \n",
    "        y_proba = model(X)\n",
    "        _, y_pred = torch.max(y_proba.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (y_pred == y).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        X, y = data\n",
    "        if device.type != 'cpu':\n",
    "            X, y = X.to(device), y.to(device) \n",
    "        y_proba = model(X)\n",
    "        _, y_pred = torch.max(y_proba, 1)\n",
    "        c = (y_pred == y).squeeze()\n",
    "        for i in range(4):\n",
    "            label = y[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_activation_image(target):\n",
    "    zeros = np.zeros((1,3,32,32)).astype(np.float32)\n",
    "    gray = zeros+0.5\n",
    "    X = torch.tensor(gray, requires_grad=True)\n",
    "    target = torch.empty(1, dtype=torch.long).random_(target,target+1)\n",
    "    # plot_image(gray)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i in range(100):\n",
    "        # y probabilities [p0,p1,...,p9]\n",
    "        y_proba = model(X)\n",
    "\n",
    "        #backward\n",
    "        loss = criterion(y_proba, target)\n",
    "        loss.backward()\n",
    "\n",
    "        #minimize loss\n",
    "        X.data -= 0.15*X.grad.data    \n",
    "\n",
    "        X.grad.data.zero_()\n",
    "        \n",
    "#         if i%10 ==0:\n",
    "#             IPython.display.display(plt.gcf())       # Tell Jupyter to show Matplotlib's current figure\n",
    "#             IPython.display.clear_output(wait=True)  # Tell Jupyter to clear whatever it's currently showing\n",
    "#             time.sleep(0.02)\n",
    "    plt.title(\"Target class: %s\"%classes[target])\n",
    "    plot_image(X[0].detach().numpy())\n",
    "    plt.savefig(IMAGE_PATH+classes[target]+'_activation')\n",
    "    print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this is animation\n",
    "model = model.cpu()\n",
    "plt.figure(figsize=(25,10))\n",
    "for i in range(1):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plot_activation_image(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
